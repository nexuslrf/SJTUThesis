\chapter{AVPipe视频任务代码片段}\label{app:code}
\begin{codeblock}[language=C++, basicstyle=\ttfamily\footnotesize, numbers=left, caption=Pose Example]\label{code:pose}
// This cpp file is generated by AVP\_Automation
// Author: RF Liang, 2020
#include <iostream>
#include <string>
#include <vector>
#include <avpipe/helper_func.hpp>
#include <cv_compute/cv_stream_src.hpp>
#include <cv_compute/cv_transformation.hpp>
#include <tensor_compute/tensor_utils.hpp>
#include <tensor_compute/openvino.hpp>
#include <tensor_compute/libtorch.hpp>
#include <tensor_compute/det_postprocess.hpp>
#include <cv_compute/cv_rendering.hpp>
#include <cv_compute/cv_display.hpp>

int main()
{
    // Initialize necessary parameters for AVP
    avp::numThreads = 3;
    avp::streamCapacity = 5;

    // Start processor definition
    avp::VideoFileProcessor videoSrc("video_file.mp4", "videoSrc");
    avp::CenterCropResize crop(videoSrc.rawHeight, videoSrc.rawWidth, 256, 192, false, false, "crop");
    avp::ImgNormalization normalization({0.485, 0.456, 0.406}, {0.229, 0.224, 0.225}, "normalization");
    avp::DataLayoutConvertion matToTensor(avp::NHWC, avp::NCHW, "matToTensor");
    avp::OpenVinoProcessor CNN({1, 3, 256, 192}, avp::NCHW, "CNN_file", 1, "CNN");
    avp::LibTorchProcessor filter({1, 17, 64, 48}, avp::NCHW, "filter_file", 1, "filter");
    avp::LandMarkMaxPred maxPred(true, "maxPred");
    avp::PredToKeypoint getKeypoint(2, "getKeypoint");
    avp::DrawLandMarks draw(4, 4, 0, 0, 0.3, 2, {0, 0, 255}, "draw");
    avp::StreamShowProcessor imshow(1, "", "imshow");

    // Start pipe binding
    avp::Stream pipe[11];
    videoSrc.bindStream({}, {&pipe[0]});
    crop.bindStream({&pipe[0]}, {&pipe[1]});
    normalization.bindStream({&pipe[10]}, {&pipe[2]});
    matToTensor.bindStream({&pipe[2]}, {&pipe[3]});
    CNN.bindStream({&pipe[3]}, {&pipe[4]});
    filter.bindStream({&pipe[4]}, {&pipe[5]});
    maxPred.bindStream({&pipe[4]}, {&pipe[6], &pipe[7]});
    getKeypoint.bindStream({&pipe[5], &pipe[6]}, {&pipe[8]});
    draw.bindStream({&pipe[8], &pipe[1], &pipe[7]}, {&pipe[9]});
    imshow.bindStream({&pipe[9]}, {});

    // Couple streams for multi-threading
    pipe[1].coupleStream({&pipe[10]});
    
    // Start running pipe
    // Create threads
    std::vector<std::thread> avp_threads;
    
    avp_threads.push_back(std::thread(avp::pipeThreadProcess, avp::ProcList({&videoSrc, &crop, &normalization, &matToTensor}), 50));
    avp_threads.push_back(std::thread(avp::pipeThreadProcess, avp::ProcList({&CNN}), 50));
    avp::pipeThreadProcessTiming(avp::ProcList({&filter, &maxPred, &getKeypoint, &draw, &imshow}), 50);

    // Wait for joining
    for(auto& thread: avp_threads)
        thread.join();

    std::cout<<"\nAVP finish!\n";
    return 0;
}
\end{codeblock}
\newpage
\begin{codeblock}[language=C++, basicstyle=\ttfamily\footnotesize, numbers=left, caption=Hand Example]\label{code:hand}
// This cpp file is generated by AVP\_Automation
// Author: RF Liang, 2020
#include <iostream>
#include <string>
#include <vector>
#include <avpipe/helper_func.hpp>
#include <cv_compute/cv_stream_src.hpp>
#include <cv_compute/cv_transformation.hpp>
#include <tensor_compute/tensor_utils.hpp>
#include <tensor_compute/onnx_runtime.hpp>
#include <tensor_compute/det_postprocess.hpp>
#include <cv_compute/cv_rendering.hpp>
#include <cv_compute/cv_display.hpp>

int main()
{
    // Initialize necessary parameters for AVP
    avp::numThreads = 4;
    avp::streamCapacity = 5;

    // Start processor definition
    avp::WebCamProcessor videoSrc(0, "videoSrc");
    avp::CenterCropResize crop(videoSrc.rawHeight, videoSrc.rawWidth, 256, 256, false, true, "crop");
    avp::ImgNormalization normalization(0.5, 0.5, "normalization");
    avp::DataLayoutConvertion matToTensor(avp::NHWC, avp::NCHW, "matToTensor");
    avp::ONNXRuntimeProcessor PalmCNN({1, 3, 256, 256}, avp::NCHW, "palm_detection.onnx", 2, "PalmCNN");
    avp::DecodeDetBoxes decodeBoxes(2944, "anchors.bin", 256, 256, 7, "decodeBoxes");
    avp::NonMaxSuppression NMS(7, 100.0, 0.8, 0.3, "NMS");
    avp::RotateCropResize palmRotateCropResize(256, 256, crop.cropHeight, crop.cropWidth, 2, 0, 0.5, 0, 2.6, true, true, "palmRotateCropResize");
    avp::ImgNormalization normalization2(0.5, 0.5, "normalization2");
    avp::DataLayoutConvertion multiCropToTensor(avp::NHWC, avp::NCHW, "multiCropToTensor");
    avp::ONNXRuntimeProcessor HandCNN({0, 3, 256, 256}, avp::NCHW, "blaze_hand.onnx", 2, "HandCNN");
    avp::RotateBack rotateBack(256, 256, 21, 0.8, "rotateBack");
    avp::DrawLandMarks drawKeypoint(1.0, 1.0, 0, 0, 0, 4, {0, 0, 255}, "drawKeypoint");
    avp::StreamShowProcessor imshow_kp(1, "", "imshow_kp");

    // Start pipe binding
    avp::Stream pipe[21];
    videoSrc.bindStream({}, {&pipe[0]});
    crop.bindStream({&pipe[0]}, {&pipe[1], &pipe[2]});
    normalization.bindStream({&pipe[1]}, {&pipe[3]});
    matToTensor.bindStream({&pipe[3]}, {&pipe[4]});
    PalmCNN.bindStream({&pipe[4]}, {&pipe[5], &pipe[6]});
    decodeBoxes.bindStream({&pipe[5]}, {&pipe[7]});
    NMS.bindStream({&pipe[7], &pipe[6]}, {&pipe[8], &pipe[9]});
    palmRotateCropResize.bindStream({&pipe[8], &pipe[9], &pipe[20]}, {&pipe[10], &pipe[11], &pipe[12], &pipe[13]});
    normalization2.bindStream({&pipe[10]}, {&pipe[14]});
    multiCropToTensor.bindStream({&pipe[14]}, {&pipe[15]});
    HandCNN.bindStream({&pipe[15]}, {&pipe[16], &pipe[17]});
    rotateBack.bindStream({&pipe[16], &pipe[17], &pipe[13], &pipe[11], &pipe[12]}, {&pipe[18]});
    drawKeypoint.bindStream({&pipe[18], &pipe[2]}, {&pipe[19]});
    imshow_kp.bindStream({&pipe[19]}, {});

    // Couple streams for multi-threading
    pipe[2].coupleStream({&pipe[20]});

    // Start running pipe
    // Create threads
    std::vector<std::thread> avp_threads;

    avp_threads.push_back(std::thread(avp::pipeThreadProcess, avp::ProcList({&videoSrc, &crop, &normalization, &matToTensor}), 50));
    avp_threads.push_back(std::thread(avp::pipeThreadProcess, avp::ProcList({&PalmCNN}), 50));
    avp_threads.push_back(std::thread(avp::pipeThreadProcess, avp::ProcList({&decodeBoxes, &NMS, &palmRotateCropResize, &normalization2, &multiCropToTensor, 
        &HandCNN}), 50));
    avp::pipeThreadProcessTiming(avp::ProcList({&rotateBack, &drawKeypoint, &imshow_kp}), 50);

    // Wait for joining
    for(auto& thread: avp_threads)
        thread.join();

    std::cout<<"\nAVP finish!\n";

    return 0;
}
\end{codeblock}