% !TEX root = ../thesis.tex

\chapter{相关工作}\label{related_work}
针对深度学习相关的视频处理优化属于在近年来兴起的研究课题，针对性的相关工作并不是很多。本章对一些较出名的相关项目进行介绍，同时对本框架中所涉及的技术与优化相关算法的现有工作做一简单介绍。

\section{视频流处理框架}
% 介绍 DataFlow, GStream，，Graph-API, MediaPipe, videoFlow
首先，GStreamer\cite{gstreamer}是一个以计算图的形式来创建有关流媒体的处理流程的开源框架，GStreamer最初于2001年发布，它支持多种流水线的构建，并且包含丰富的音、视频处理模块。但这个框架主要用于更为底层的音视频信号编辑与整合，而非本文所关注的视频内容的智能分析处理。\par
Dataflow\cite{akidau2015dataflow}是在2015年推出的数据流分析框架，它被应用在Google Cloud上提供云端数据流的分析与推理能力。该框架提供了对数据流处理的计算关系图的定义，但是该框架是应用在云端集群上并且以批量数据块为基本对象的模型。这并不适用于与构建用户端本地视频流处理部署，以数据流为处理对象的应用场景。\par 
OpenCV在其4.0版本中引入了Graph API\cite{matveev2018opencv}，这一API可以使用户通过计算图的形式定义一系列对图像
的处理流程，然而Graph API的局限性在于它处理流程是基于OpenCV中Mat数据封装来进行的，因此处理流程需要依赖OpenCV对各类图像处理算法的支持，同时Mat的数据封装对神经网络推理所需要用到的高维张量的表示能力有限，无法完整定义在整个视频检测分析处理流程。\par
Videoflow\cite{deArmas2019videoflow}是一个于2019年开源的Python的视频流处理框架。它提供了对视频流处理完整步骤的简单的图定义，帮助开发人员快速完成视频处理算法的原型开发。Videoflow仅对处理流程图提供简单的数据同步管理，缺少针对性优化。此外Python语言的使用也限制了该框架的进一步性能优化以及实际部署应用。\par
MediaPipe\cite{lugaresi2019mediapipe}是Google在2019年CVPR上公开的数据流处理机器学习应用开发框架。
它用定义计算图的方式，构建使用了多种形式时间序列数据（如视频、音频以及传感器数据）进行机器学习分析推理流程的框架。针对流数据处理任务的快速部署与应用，MediaPipe使用TensorFlow\cite{abadi2016tensorflow}做为其深度学习推理引擎，提供多平台的支持与加速，包括各大桌面与移动平台。相比之前的数据流出框架，MediaPipe提供更为灵活的数据传输管道以及计算图定义。MediaPipe使用线程池模型将处于计算图中的不同阶段的数据包进行动态调度到不同的线程中运行。MediaPipe框架确实为流媒体分析处理应用的创建与部署提供了很大的帮助，但MediaPipe项目也有其局限性。首先，和其他很多Google开源项目一样，MediaPipe使用了很多Google自有的代码库与模块进行构建，自定义MediaPipe的计算模块对普通用户来说有较高的学习成本；其次，MediaPipe目前仅支持通过TensorFlow创建的视频处理任务，这对也使得该框架无法利用一些针对性优化的深度学习推理引擎（见\ref{related:dl_engine}）来提升性能；
另外，MediaPipe的线程池模型为保证数据的依赖与同步有复杂的控制逻辑，在某些情况\footnote{如数据队列中多数数据包关联的线程需要运行高耗时的网络推理模块，但计算资源不能支持同时进行多个网络推理，从而造成多数线程的阻塞。}下需要用户手动调整不同线程的计算范围。\par
本研究所提出的Accel-Video Pipe对以上项目的优点都有所借鉴。MediaPipe作为如今最受关注的相关项目，目前仍在处于积极开发阶段。我们期望AV Pipe框架能够有MediaPipe相当的可用性，并对MediaPipe所存在的局限进行优化与改进。\par
\section{深度学习推理引擎}\label{related:dl_engine}
如\ref{sub:infer_opt}中所说，深度学习算法的成熟应用促进了相关优化计算引擎的发展。以下对AV\~  Pipe框架中所使用或提供支持的深度学习推理引擎进行介绍。\par
LibTorch是Facebook开源机器学习框架PyTorch\cite{paszke2019pytorch}的C++前端接口。它集成了Caffe2\cite{markham2017caffe2}框架中的张量（Tensor）实现以及丰富的Tensor运算算子。LibTorch提供了完善的多平台支持。减少了Python前端对C++后端库的调用开销，并且对多线程应用场景有了更好支持。LibTorch支持对TorchScript模型的即时编译运行（Just-in-time， JIT），而TorchScript可由原始PyTorch模型进行简单张量追踪获得。\par
ONNX Runtime\cite{onnxruntime}是Microsoft开源的支持ONNX（Open Neural Network Exchange）\cite{onnx}格式模型的机器学习推理框架，ONNX Runtime通过对ONNX的优化与划分，将整个模型合理分配到多种后端计算库或计算设备上，从而实现模型推理加速。对多种计算库的支持需要依赖ONNX Runtime与相应库的联合编译，其提供的C++接口仅提供对机器学习模型推理运算，模型的输入输出为原始数据指针的形式，此外ONNX Runtime框架的初始化和配置较为复杂，有一定的部署与应用成本。\par
OpenVINO\cite{openvino}是Intel为其包括CPU，GPU，FPGA，VPU在内的多种计算芯片提供神经网络推理加速的框架。OpenVINO采用离线优化的形式，将来自不同网络训练框架的模型通过算子融合，算子替换，模型量化等方式生成优化后神经网络中间表示（Intermediate Representation，IR）\cite{cyphers2018intel}，以供Intel高性能计算库如MKL-DNN\cite{mkldnn}等来进行调用。
与OpenVINO类似，TensorRT\cite{tensorrt}是Nvidia为其GPU产品提供的推理加速引擎。TensorRT同样会对网络模型进行预优化，减少算子对相关算子的调用，优化对显存使用。与OpenVINO同样的局限在于这类推理加速引擎只能用在其自家的计算芯片上。\par
TVM\cite{chen2018tvm}是由Chen et al.提出的一个端到端的深度学习模型部署编译框架。TVM针对不同硬件不同平台提供针对性的计算图优化空间。用户可以自定义不同算子到底层硬件的映射方式。TVM也提供AutoTVM工具用机器学习的方式自动搜索最优的算子编译方式。TVM目前仍在积极开发状态，它的多平台支持，参考文档，以及自动优化的使用场景还有着许多不完善的地方。现阶段使用TVM对进行神经网络的部署与优化还存在较高的硬件与学习成本。\par
% @TODO 在这里加一个运行速度对比的表格！
我们的AVPipe会对以上提及的神经网络推理引擎进行不同程度的支持，将更为统一和简洁的函数接口提供给用户，以满足不同硬件以及平台下的视频流处理的高效进行。
\section{DAG任务的调度与划分}
% 多阶段有依赖任务的调度与划分
在\ref{intro_vp}中，我们将视频流处理的过程抽象为一个持续运行的固定的有向无环图（DAG）。基于这样的特点，我们期望通过对处理流程的DAG的调度或划分来完成AVPipe的自动流处理优化。\par
DAG图的调度与划分是指将DAG图中的计算结点分配到不同的处理器或线程上，通过并行的方式，减少处理DAG任务所需的时间。
对一般DAG运行图的调度与划分早在1979就被证明是NP-Complete问题\cite{garey1979computers}，即便对简单的结点运行时间只可能是1或2时间单元的DAG处理任务，将其最优分配到2个线程上也被证明是NP-Complete问题。因此，对于一般DAG图计算的优化多采用与其应用领域相关的启发式算法或近似算法来实现\cite{kwok1999static}。以下对一些的有关调度随机DAG图的启发式算法做一介绍。\par
首先是基于运行时长与拓扑排序的启发式算法。这类算法一般依据DAG图的结构以及每个结点所需要的运行时间，对结点按其可运行时间以及拓扑顺序进行排序。依据这类排序，算法将运行结点按不同的假设放入不同的线程中。如HLFET（Highest Level First with Estimated Times）算法\cite{adam1974comparison}直接按排序对结点进行顺序分配，MCP（Modified Critical Path）算法\cite{wu1990hypertool}，在分配结点的同时，MCP会尽可能将待运行结点分配到对存在合适调度时间间隙的线程或处理器上。这类算法并没有对结点的分叉与汇合进行特殊考虑，这在某些结点分布不平衡的线程或处理器上可能会因依赖阻塞造成计算资源的闲置。\par
也有使用分支定界（branch-and-bound）的方式，利用整数规划方程来寻找DAG处理流程的有效划分 \cite{nossack2014branch}，这种方法可以得到近似最优的划分结果，但其建模与计算都相对复杂，在实际场景中应用有限。此外还有基于聚类方法的对计算结点的划分\cite{wong2003clustering}，聚类方式可以确保存在分叉或汇合的结点不会在划分的过程中不存在由于部分来自其他线程或处理器的依赖造成的阻塞闲置。\par
针对本文讨论的多阶段视频流处理任务的优化，我们会考虑利用时间信息的拓扑排序在进行运行结点的分配，对视频流处理中可能存在的复杂数据依赖我们也会考虑通过聚类的方式提高处理线程中时间与空间的局部性（locality）。\par

\section{本章小结}
本章介绍了AVPipe较为相关的几个研究方向中现有的有较高影响度的工作。由对新兴视频流处理框架的介绍，可以看出目前这方面的应用方案并不完全成熟，各个框架存在的局限也使得确保我们所要实现的AVPipe框架有其现实意义，并非重复造轮子的无用功。神经网络的编译与推理引擎，也在随着深度学习技术进步而持续发展，在这之中TVM技术栈有更为长远技术目标，这会对未来AVPipe的多平台多硬件实践提供很大的支持，AVPipe框架的原型也会在今后持续跟进相关技术的发展。对DAG处理流程的调度与划分是学术界一直以来都在研究的问题，由于其NP-Complete的特点，这使得我们结合具体任务提出针对性的启发算法，对已有算法的学习与借鉴会对我们自己算设计提供很大程度的帮助。